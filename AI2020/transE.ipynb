{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fknHs0U8q2Bj"
      },
      "source": [
        "# **개체 (Entity)**\n",
        "\n",
        "정의 : 인간의 개념 또는 정보의 세계에서 의미있는 하나의 정보 단위\n",
        "\n",
        "EX) 위키피디아의 페이지\n",
        "[거미(가수)](https://https://ko.wikipedia.org/wiki/%EA%B1%B0%EB%AF%B8_(%EA%B0%80%EC%88%98))\n",
        "\n",
        "![python image2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqLemd%2FbtqM2G8JWTi%2FVelDRmXccGW9L0XSGrlRy0%2Fimg.png)\n",
        "\n",
        "이러한 개체들의 관계를 이용하여 Triple, 그래프의 형태로 표현이 가능\n",
        "\n",
        "**<개체 1, 관계, 개체 2>**\n",
        "\n",
        "**<Subject, Relation, Object>**\n",
        "\n",
        "**<Head, Predicate, Tail>**\n",
        "\n",
        "**EX)**\n",
        "\n",
        "**<거미, 성별, 여자>**\n",
        "\n",
        "**<거미, 직업, 가수>**\n",
        "\n",
        "**<거미, 배우자, 조정석>**\n",
        "\n",
        "**...**\n",
        "\n",
        "![python image2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJ1iWc%2FbtqM0q59rTe%2FuK81rXhfWsCLukQXGKIo50%2Fimg.png)\n",
        "\n",
        "# **TransE**\n",
        "\n",
        "그래프 임베딩의 한 방법 (Translation-based)\n",
        "\n",
        "모든 개체와 관계에 대해서 Subject + Relation = Object가 되도록 모델을 학습\n",
        "\n",
        "![python image2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2rojl%2FbtqMTgDd9KD%2FwNecWHJXitVQNpT9uKa67k%2Fimg.png)\n",
        "\n",
        "![python image2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fn53YR%2FbtqMRkspbpg%2FCcTE6O0f0zGDkuLbUShhZ1%2Fimg.png)\n",
        "\n",
        "##Negative Sampling\n",
        "\n",
        "TransE 모델을 학습하기 위한 방법\n",
        "\n",
        "정답(Positive) Triple과 오답(Negative) Triple의 거리가 멀어지도록 학습\n",
        "\n",
        "loss(x1,x2,y)=max(0,(positive−negative)+margin)\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html\n",
        "\n",
        "![python image2](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcLC1V5%2FbtqMThoFHpW%2FjqkGbCwfTlsubfYo227XA1%2Fimg.png)\n",
        "\n",
        "# **Link Prediction**\n",
        "\n",
        "<Subject, Relation, X> 혹은 <X, Relation, Object>가 주어졌을 때, X에 해당하는 개체를 찾는 문제\n",
        "\n",
        "## Benchmark Dataset\n",
        "\n",
        "FB15K 데이터셋\n",
        "\n",
        "Freebase를 이용하여 구성된 데이터셋\n",
        "\n",
        "개체 ID : /m/027rn \n",
        "\n",
        "위키데이터 : https://www.wikidata.org/wiki/Q786\n",
        "\n",
        "위키피디아 : https://ko.wikipedia.org/wiki/%EB%8F%84%EB%AF%B8%EB%8B%88%EC%B9%B4_%EA%B3%B5%ED%99%94%EA%B5%AD\n",
        "\n",
        "쿼리 검색 : https://query.wikidata.org/#PREFIX%20wd%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fentity%2F%3E%0APREFIX%20wdt%3A%20%3Chttp%3A%2F%2Fwww.wikidata.org%2Fprop%2Fdirect%2F%3E%0APREFIX%20wikibase%3A%20%3Chttp%3A%2F%2Fwikiba.se%2Fontology%23%3E%0A%0ASELECT%20%20%3Fs%20%3FsLabel%20%3Fp%20%3Fo%20%3FoLabel%20WHERE%20%7B%0A%20%3Fs%20%3Fp%20%3Fo%20.%0A%20%3Fs%20wdt%3AP646%20%22%2Fm%2F027rn%22%20.%0A%0A%20%20%20SERVICE%20wikibase%3Alabel%20%7B%0A%20%20%20%20bd%3AserviceParam%20wikibase%3Alanguage%20%22en%22%20.%0A%20%20%20%7D%0A%20%7D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWTDcPHGCYSl"
      },
      "source": [
        "###임포트 및 하이퍼 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1m7vsPJB8d4"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "\n",
        "model_path = '/train_model/best_model'\n",
        "data_path = '/data/FB15K'\n",
        "train_batch_size = 1024\n",
        "eval_batch_size = 512\n",
        "epochs = 100 # 2000\n",
        "learning_rate = 0.1\n",
        "\n",
        "hidden_size = 50\n",
        "eval_freq = 25\n",
        "margin = 1.\n",
        "seed = 3435\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CYDdH2rC0hs"
      },
      "source": [
        "###Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3Ra8gbKDfLo"
      },
      "source": [
        "def load_dict(path) :\n",
        "    output_dict = {}\n",
        "\n",
        "    for line in open(path, 'r').readlines()[1:] :\n",
        "        key, value = line.strip().split('\\t')\n",
        "        output_dict[key] = int(value)\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "class FB15K_Dataset(data.Dataset) :\n",
        "    def __init__(self, path, entity2id, relation2id):\n",
        "        self.entity2id = entity2id\n",
        "        self.relation2id = relation2id\n",
        "\n",
        "        self.data = []\n",
        "        for line in open(path, 'r').readlines()[1:]:\n",
        "            self.data.append(list(map(int, line.strip().split())))\n",
        "            # str -> int (sbj_id, obj_id, rel_id)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.data[item]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnlTfXiQDyh9"
      },
      "source": [
        "###데이터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ROU6ZprD-HO",
        "outputId": "fa5026b7-6aa9-4cf2-9082-c7ad06a90d69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 1. Load data set\n",
        "entity2id = load_dict(os.path.join(data_path, 'entity2id.txt'))\n",
        "relation2id = load_dict(os.path.join(data_path, 'relation2id.txt'))\n",
        "\n",
        "train_dataset = FB15K_Dataset(os.path.join(data_path, 'train2id.txt'), entity2id, relation2id)\n",
        "dev_dataset = FB15K_Dataset(os.path.join(data_path, 'valid2id.txt'), entity2id, relation2id)\n",
        "test_dataset = FB15K_Dataset(os.path.join(data_path, 'test2id.txt'), entity2id, relation2id)\n",
        "\n",
        "train_loader = data.DataLoader(train_dataset,\n",
        "                               batch_size=train_batch_size,\n",
        "                               shuffle=True)\n",
        "dev_loader = data.DataLoader(dev_dataset,\n",
        "                             batch_size=eval_batch_size,\n",
        "                             shuffle=False)\n",
        "test_loader = data.DataLoader(test_dataset,\n",
        "                              batch_size=eval_batch_size,\n",
        "                              shuffle=False)\n",
        "\n",
        "print('entity to id : ', [(key, val) for key, val in entity2id.items()][:5])\n",
        "print('relation to id : ', [(key, val) for key, val in relation2id.items()][:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entity to id :  [('/m/027rn', 0), ('/m/06cx9', 1), ('/m/017dcd', 2), ('/m/06v8s0', 3), ('/m/07s9rl0', 4)]\n",
            "relation to id :  [('/location/country/form_of_government', 0), ('/tv/tv_program/regular_cast./tv/regular_tv_appearance/actor', 1), ('/media_common/netflix_genre/titles', 2), ('/award/award_winner/awards_won./award/award_honor/award_winner', 3), ('/soccer/football_team/current_roster./sports/sports_team_roster/position', 4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xmLmg_aHmTR"
      },
      "source": [
        "### 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5TO73bZHn80"
      },
      "source": [
        "\n",
        "class TransE(nn.Module):\n",
        "    def __init__(self, n_entity, n_relation, hidden_size, margin=1.0, device=True):\n",
        "        super(TransE, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.n_entity = n_entity\n",
        "        self.n_relation = n_relation\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.entity_embedding = nn.Embedding(self.n_entity + 1, self.hidden_size, padding_idx=self.n_entity)\n",
        "        self.relation_embedding = nn.Embedding(self.n_relation + 1, self.hidden_size, padding_idx=self.n_relation)\n",
        "\n",
        "        self.init_weight(self.entity_embedding)\n",
        "        self.init_weight(self.relation_embedding)\n",
        "\n",
        "        self.loss_func = nn.MarginRankingLoss(margin=margin, reduction='none')\n",
        "\n",
        "    def init_weight(self, embedding):\n",
        "        n_vocab, hidden_dim = embedding.weight.data.size()\n",
        "        sqrt_dim = hidden_dim ** 0.5\n",
        "\n",
        "        embedding.weight.data = torch.FloatTensor(n_vocab, hidden_dim).uniform_(-6./sqrt_dim, 6./sqrt_dim)\n",
        "        embedding.weight.data = F.normalize(embedding.weight.data, 2, 1)\n",
        "\n",
        "    def get_score(self, triple):\n",
        "        sbj, rel, obj = triple[:, 0], triple[:, 1], triple[:, 2]\n",
        "\n",
        "        sbj_embedding = self.entity_embedding(sbj)\n",
        "        rel_embedding = self.relation_embedding(rel)\n",
        "        obj_embedding = self.entity_embedding(obj)\n",
        "\n",
        "        score = torch.norm((sbj_embedding + rel_embedding - obj_embedding), p=1, dim=1)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def forward(self, positive_triple, negative_triple):\n",
        "        positive_score = self.get_score(positive_triple)\n",
        "        negative_score = self.get_score(negative_triple)\n",
        "\n",
        "        y = torch.tensor([-1.], dtype=torch.float, device=self.device)\n",
        "\n",
        "        return self.loss_func(positive_score, negative_score, y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rvCkLpSIaSk"
      },
      "source": [
        "###모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUMdeFqzIdUC"
      },
      "source": [
        "def hit_at_k(pred, answer, device, k=10) :\n",
        "    zero_tensor = torch.tensor([0], device=device)\n",
        "    one_tensor = torch.tensor([1], device=device)\n",
        "\n",
        "    _, indices = pred.topk(k=k, largest=False)\n",
        "\n",
        "    return torch.where(indices == answer.unsqueeze(1), one_tensor, zero_tensor).sum().item()\n",
        "\n",
        "def MRR(pred, answer) :\n",
        "    return (1. / (pred.argsort() == answer.unsqueeze(1)).nonzero()[:, 1].float().add(1.)).sum().item()\n",
        "\n",
        "def evaluation(model, data_loader, device) :\n",
        "    model.eval() # evaluation mode\n",
        "    hit_at_1, hit_at_3, hit_at_10, mrr, total = 0., 0., 0., 0., 0.\n",
        "\n",
        "    entity_ids = torch.arange(model.n_entity, device=device).unsqueeze(0)\n",
        "\n",
        "    for sbj, obj, rel in data_loader :\n",
        "        sbj, rel, obj = sbj.to(device), rel.to(device), obj.to(device)  # to GPU\n",
        "        b_size = sbj.size(0)\n",
        "\n",
        "        all_entity = entity_ids.repeat(b_size, 1)\n",
        "        repeat_sbj = sbj.unsqueeze(1).repeat(1, all_entity.size(1))\n",
        "        repeat_rel = rel.unsqueeze(1).repeat(1, all_entity.size(1))\n",
        "        repeat_obj = obj.unsqueeze(1).repeat(1, all_entity.size(1))\n",
        "\n",
        "        sbj_triples = torch.stack((repeat_sbj, repeat_rel, all_entity), dim=2).view(-1, 3)\n",
        "        obj_triples = torch.stack((all_entity, repeat_rel, repeat_obj), dim=2).view(-1, 3)\n",
        "\n",
        "        obj_pred_score = model.get_score(sbj_triples).view(b_size, -1)\n",
        "        sbj_pred_score = model.get_score(obj_triples).view(b_size, -1)\n",
        "\n",
        "        pred = torch.cat([sbj_pred_score, obj_pred_score], dim=0)\n",
        "        answer = torch.cat([sbj, obj], dim=0)\n",
        "\n",
        "        hit_at_1 += hit_at_k(pred, answer, device, k=1)\n",
        "        hit_at_3 += hit_at_k(pred, answer, device, k=3)\n",
        "        hit_at_10 += hit_at_k(pred, answer, device, k=10)\n",
        "\n",
        "        mrr += MRR(pred, answer)\n",
        "        total += pred.size(0)\n",
        "\n",
        "    hit_at_1_score = hit_at_1 / total * 100.\n",
        "    hit_at_3_score = hit_at_3 / total * 100.\n",
        "    hit_at_10_score = hit_at_10 / total * 100.\n",
        "    mrr_score = mrr / total * 100.\n",
        "\n",
        "    return hit_at_1_score, hit_at_3_score, hit_at_10_score, mrr_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i9FEbx7Htyk"
      },
      "source": [
        "###모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I4W_WpwHvRo",
        "outputId": "1096bed9-1804-46f7-cf9b-dc785a76f8d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2. Model\n",
        "model = TransE(n_entity=len(entity2id),\n",
        "                n_relation=len(relation2id),\n",
        "                hidden_size=hidden_size,\n",
        "                margin=margin,\n",
        "                device=device)\n",
        "model.to(device) # to GPU\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print('Model Structure : {}'.format(model))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Structure : TransE(\n",
            "  (entity_embedding): Embedding(14952, 50, padding_idx=14951)\n",
            "  (relation_embedding): Embedding(1346, 50, padding_idx=1345)\n",
            "  (loss_func): MarginRankingLoss()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpkcCullH0Ao"
      },
      "source": [
        "### 학습 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqnDXF-cIppE",
        "outputId": "4636d086-521b-4d98-8a76-ba1575bdedd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 3. Training\n",
        "best_score = 0.\n",
        "for epoch in range(1, epochs+1) :\n",
        "    model.train() # train mode\n",
        "    for i, (sbj, obj, rel) in enumerate(train_loader) :\n",
        "        sbj, rel, obj = sbj.to(device), rel.to(device), obj.to(device)  # to GPU\n",
        "\n",
        "        positive_triples = torch.stack((sbj, rel, obj), dim=1) # (batch) * 3 -> (batch, 3)\n",
        "\n",
        "        # Negative sampling\n",
        "        head_or_tail = torch.randint(high=2, size=sbj.size(), device=device)\n",
        "        random_entities = torch.randint(high=len(entity2id), size=sbj.size(), device=device)\n",
        "        neg_sbj = torch.where(head_or_tail == 1, random_entities, sbj)\n",
        "        neg_obj = torch.where(head_or_tail == 0, random_entities, obj)\n",
        "        negative_triples = torch.stack((neg_sbj, rel, neg_obj), dim=1) # (batch) * 3 -> (batch, 3)\n",
        "\n",
        "        loss = model(positive_triples, negative_triples).mean()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    print('Epoch = {}, loss = {:.6f}'. format(epoch, loss))\n",
        "    if(epoch % eval_freq == 0) :\n",
        "        print('evaluation...')      \n",
        "        hit_at_1_score, hit_at_3_score, hit_at_10_score, mrr_score = evaluation(model, dev_loader, device)\n",
        "\n",
        "        print('Dev set >> hit@1 : {:.2f}, hit@3 : {:.2f}, hit@10 : {:.2f}, mrr : {:.2f}'.format(hit_at_1_score,\n",
        "                                                                                                hit_at_3_score,\n",
        "                                                                                                hit_at_10_score,\n",
        "                                                                                                mrr_score))\n",
        "        if(hit_at_10_score > best_score) :\n",
        "            print('best model save...')\n",
        "            state_dict = model.state_dict()\n",
        "            torch.save(state_dict, model_path)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "hit_at_1_score, hit_at_3_score, hit_at_10_score, mrr_score = evaluation(model, test_loader, device)\n",
        "\n",
        "print('Test Set >> hit@1 : {:.2f}, hit@3 : {:.2f}, hit@10 : {:.2f}, mrr : {:.2f}'.format(hit_at_1_score,\n",
        "                                                                                         hit_at_3_score,\n",
        "                                                                                         hit_at_10_score,\n",
        "                                                                                         mrr_score))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch = 1, loss = 0.880901\n",
            "Epoch = 2, loss = 0.906595\n",
            "Epoch = 3, loss = 0.850646\n",
            "Epoch = 4, loss = 0.873005\n",
            "Epoch = 5, loss = 0.835165\n",
            "Epoch = 6, loss = 0.783515\n",
            "Epoch = 7, loss = 0.746253\n",
            "Epoch = 8, loss = 0.748630\n",
            "Epoch = 9, loss = 0.684783\n",
            "Epoch = 10, loss = 0.699624\n",
            "Epoch = 11, loss = 0.691527\n",
            "Epoch = 12, loss = 0.608379\n",
            "Epoch = 13, loss = 0.624080\n",
            "Epoch = 14, loss = 0.607351\n",
            "Epoch = 15, loss = 0.589332\n",
            "Epoch = 16, loss = 0.608591\n",
            "Epoch = 17, loss = 0.594701\n",
            "Epoch = 18, loss = 0.575374\n",
            "Epoch = 19, loss = 0.577998\n",
            "Epoch = 20, loss = 0.566708\n",
            "Epoch = 21, loss = 0.547071\n",
            "Epoch = 22, loss = 0.528131\n",
            "Epoch = 23, loss = 0.468423\n",
            "Epoch = 24, loss = 0.500543\n",
            "Epoch = 25, loss = 0.501337\n",
            "evaluation...\n",
            "Dev set >> hit@1 : 1.06, hit@3 : 3.84, hit@10 : 7.92, mrr : 3.43\n",
            "best model save...\n",
            "Epoch = 26, loss = 0.458003\n",
            "Epoch = 27, loss = 0.443243\n",
            "Epoch = 28, loss = 0.476310\n",
            "Epoch = 29, loss = 0.450943\n",
            "Epoch = 30, loss = 0.396407\n",
            "Epoch = 31, loss = 0.472788\n",
            "Epoch = 32, loss = 0.438596\n",
            "Epoch = 33, loss = 0.432279\n",
            "Epoch = 34, loss = 0.413685\n",
            "Epoch = 35, loss = 0.403520\n",
            "Epoch = 36, loss = 0.433478\n",
            "Epoch = 37, loss = 0.405101\n",
            "Epoch = 38, loss = 0.374304\n",
            "Epoch = 39, loss = 0.401777\n",
            "Epoch = 40, loss = 0.408653\n",
            "Epoch = 41, loss = 0.399623\n",
            "Epoch = 42, loss = 0.393858\n",
            "Epoch = 43, loss = 0.342929\n",
            "Epoch = 44, loss = 0.388975\n",
            "Epoch = 45, loss = 0.381277\n",
            "Epoch = 46, loss = 0.334471\n",
            "Epoch = 47, loss = 0.320411\n",
            "Epoch = 48, loss = 0.302753\n",
            "Epoch = 49, loss = 0.329999\n",
            "Epoch = 50, loss = 0.289979\n",
            "evaluation...\n",
            "Dev set >> hit@1 : 2.13, hit@3 : 5.66, hit@10 : 11.46, mrr : 5.28\n",
            "best model save...\n",
            "Epoch = 51, loss = 0.344359\n",
            "Epoch = 52, loss = 0.300905\n",
            "Epoch = 53, loss = 0.303976\n",
            "Epoch = 54, loss = 0.339832\n",
            "Epoch = 55, loss = 0.295746\n",
            "Epoch = 56, loss = 0.327102\n",
            "Epoch = 57, loss = 0.302980\n",
            "Epoch = 58, loss = 0.289407\n",
            "Epoch = 59, loss = 0.333655\n",
            "Epoch = 60, loss = 0.314482\n",
            "Epoch = 61, loss = 0.286334\n",
            "Epoch = 62, loss = 0.322156\n",
            "Epoch = 63, loss = 0.281036\n",
            "Epoch = 64, loss = 0.241639\n",
            "Epoch = 65, loss = 0.289615\n",
            "Epoch = 66, loss = 0.280954\n",
            "Epoch = 67, loss = 0.248506\n",
            "Epoch = 68, loss = 0.293810\n",
            "Epoch = 69, loss = 0.288214\n",
            "Epoch = 70, loss = 0.249242\n",
            "Epoch = 71, loss = 0.249455\n",
            "Epoch = 72, loss = 0.236432\n",
            "Epoch = 73, loss = 0.288886\n",
            "Epoch = 74, loss = 0.267143\n",
            "Epoch = 75, loss = 0.276750\n",
            "evaluation...\n",
            "Dev set >> hit@1 : 2.89, hit@3 : 6.97, hit@10 : 14.03, mrr : 6.63\n",
            "best model save...\n",
            "Epoch = 76, loss = 0.237987\n",
            "Epoch = 77, loss = 0.244257\n",
            "Epoch = 78, loss = 0.218013\n",
            "Epoch = 79, loss = 0.278224\n",
            "Epoch = 80, loss = 0.220774\n",
            "Epoch = 81, loss = 0.243008\n",
            "Epoch = 82, loss = 0.193849\n",
            "Epoch = 83, loss = 0.226250\n",
            "Epoch = 84, loss = 0.225025\n",
            "Epoch = 85, loss = 0.175940\n",
            "Epoch = 86, loss = 0.191652\n",
            "Epoch = 87, loss = 0.206202\n",
            "Epoch = 88, loss = 0.203545\n",
            "Epoch = 89, loss = 0.204816\n",
            "Epoch = 90, loss = 0.215653\n",
            "Epoch = 91, loss = 0.240759\n",
            "Epoch = 92, loss = 0.212707\n",
            "Epoch = 93, loss = 0.170850\n",
            "Epoch = 94, loss = 0.190650\n",
            "Epoch = 95, loss = 0.188003\n",
            "Epoch = 96, loss = 0.176256\n",
            "Epoch = 97, loss = 0.182818\n",
            "Epoch = 98, loss = 0.208779\n",
            "Epoch = 99, loss = 0.175974\n",
            "Epoch = 100, loss = 0.164207\n",
            "evaluation...\n",
            "Dev set >> hit@1 : 3.43, hit@3 : 8.05, hit@10 : 15.82, mrr : 7.63\n",
            "best model save...\n",
            "Test Set >> hit@1 : 3.47, hit@3 : 8.24, hit@10 : 16.16, mrr : 7.76\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}